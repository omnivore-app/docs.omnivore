---
title: Importing from other Clients
editLink: true
---

# {{ $frontmatter.title }}

Omnivore allows importing data from other data sources. When using the import API, you are limited to three imports per a day.

The maximum file size for an import is 10MB, and CSV imports are limited to 5000 rows. If your import exceeds this size please email [feedback@omnivore.app](mailto:feedback@omnivore.app) for assistance.

::: warning We highly recommend using Omnivore for a few days before doing an import. This will give you a sense of the features available, how you'd like to structure your labels, and what data you'd like to have available in Omnivore.
:::

[[toc]]

## Importing data from Matter

::: warning The Matter data importer is currently in beta, if you encounter any issues please notify us at [feedback@omnivore.app](mailto:feedback@omnivore.app)
:::

Omnivore supports uploading the `Archive.zip` file generated by exporting your data from the Matter app.

Import your Matter data using the [Import Matter Archive Tool](https://omnivore.app/tools/import/matter-archive).

To export your data from Matter, go to My Account, and choose Export
data, this will send you an email with your data in a file
`Archive.zip`. Upload that file using the uploader on this page.

The importer will ingest the URLs listed in the `_matter_history.csv` file. If the Archive contains an HTML content entry for the URL, the provided content will be used. Otherwise, Omnivore will attempt to refetch the URL.

::: tip Currently the importer does not support importing highlights and notes from Matter.
:::

## Importing data from Pocket

You can import up to 20 000 articles from your Pocket account to Omnivore. 

To start the process, go to the [Integrations](https://omnivore.app/settings/integrations) page of the `Settings` section of the Web app. Connect your Pocket account. The process will run in the background and you will receive an email when itâ€™s completed.

::: tip The dropdown option will let you choose to import all your Pocket content or only the unarchived items.
:::

## Importing CSV files

Omnivore can import a list of URLs by supplying a CSV file containing the following columns:

- url: unique URL (full url of the item to be imported).
- state: Either `ARCHIVED` or `SUCCEEDED`. If set to `ARCHIVED`, the item will be archived upon import. If set to `SUCCEEDED` or left empty, the item is imported and placed in the inbox.
- labels: In the format `[Label1, Label2, Label3]`, note the square brackets (`[`,`]`) around the list of labels. Labels may be separated with quotes, which is necessary to include whitespace. Due to CSV quote escaping they will need to be doubled, for example: `"[""label 1"",""label 2""]"`. If the item has no labels this column can be empty.
- saved_at: The Unix timestamp in milliseconds the item was saved. If the item has no saved_at date, this column can be empty.
- published_at: The Unix timestamp in milliseconds the item was published. If the item has no published_at date, this column can be empty.

Example File:

```
url,state,labels,saved_at,published_at
https://jacksonh.org,SUCCEEDED,"[Handsome Developers, Profile Page]",1614556800000,1614556800000
https://jacksonh.org/blog,,,,
```

Once you have a properly structured CSV file, you can drag it into your library on the web to initiate the import. Note that Omnivore has to fetch all the URLs in your import, so its a slow process.

## Importing using the API

When importing data using the API, if you have a large number of URLs to import, it is best to use the `uploadImportFile` vs the `savePage` APIs.

The `uploadImportFile` API accepts a CSV file and performs an import in the background. The `savePage` API could encounter rate limits if used to import a large number of URLs.

An example of importing with the `uploadImportFile` API can be found here: [https://github.com/omnivore-app/import-demo](https://github.com/omnivore-app/import-demo)

## Issues with importing URLs

When importing, depending on the format of your data, URLs might be refetched by Omnivore. URLs that are no longer available online might fail to be fetched. In this case, an empty entry with just the URL should be added to your library.
